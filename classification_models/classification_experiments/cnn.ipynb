{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            img_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform if transform is not None else transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data_frame.iloc[idx]['id_code'] + '.png')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        diagnosis = self.data_frame.iloc[idx]['diagnosis']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(diagnosis, dtype=torch.long)\n",
    "\n",
    "class RetinalCNNClassifier:\n",
    "    def __init__(self, num_classes=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Use ResNet50 as the CNN backbone\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Replace the final fully connected layer to match our number of classes\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Move model to device\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Define transformation pipeline\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def train(self, train_loader, val_loader=None, num_epochs=10, learning_rate=0.0001):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss/len(train_loader)\n",
    "            epoch_accuracy = 100 * correct / total\n",
    "            \n",
    "            # Store training metrics\n",
    "            self.train_losses.append(epoch_loss)\n",
    "            self.train_accuracies.append(epoch_accuracy)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%')\n",
    "            \n",
    "            # Validation phase (if validation loader provided)\n",
    "            if val_loader:\n",
    "                val_loss, val_accuracy = self.validate(val_loader, criterion)\n",
    "                self.val_losses.append(val_loss)\n",
    "                self.val_accuracies.append(val_accuracy)\n",
    "                print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "                \n",
    "                # Update learning rate based on validation loss\n",
    "                scheduler.step(val_loss)\n",
    "            else:\n",
    "                # Update learning rate based on training loss\n",
    "                scheduler.step(epoch_loss)\n",
    "    \n",
    "    def validate(self, val_loader, criterion):\n",
    "        \"\"\"Evaluate model on validation set\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        \n",
    "        return val_loss, val_accuracy\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "        return accuracy\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        self.model.eval()\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "        return predicted.item()\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        \"\"\"Plot training (and validation) metrics\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        plt.plot(epochs, self.train_losses, 'b-', label='Training Loss')\n",
    "        if self.val_losses:\n",
    "            plt.plot(epochs, self.val_losses, 'r-', label='Validation Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.train_accuracies, 'b-', label='Training Accuracy')\n",
    "        if self.val_accuracies:\n",
    "            plt.plot(epochs, self.val_accuracies, 'r-', label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_metrics.png')\n",
    "        plt.show()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize dataset with transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = RetinalDataset(\n",
    "        csv_file='train.csv', \n",
    "        img_dir='train_images',\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Split dataset (70% train, 15% validation, 15% test)\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize and train the classifier\n",
    "    classifier = RetinalCNNClassifier(num_classes=5)\n",
    "    \n",
    "    # Train the model\n",
    "    classifier.train(train_loader, val_loader, num_epochs=10)\n",
    "    \n",
    "    # Plot training metrics\n",
    "    classifier.plot_metrics()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_accuracy = classifier.evaluate(test_loader)\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(classifier.model.state_dict(), 'retinal_cnn_model.pth')\n",
    "    \n",
    "    print(f\"Model training complete with test accuracy: {test_accuracy:.2f}%\")\n",
    "    print(\"Model saved as 'retinal_cnn_model.pth'\")\n",
    "    print(\"Training metrics visualization saved as 'training_metrics.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
