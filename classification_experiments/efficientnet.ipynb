{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\saadu/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:00<00:00, 80.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 0.7048, Train Acc: 74.37%, Val Loss: 0.5401, Val Acc: 79.96%, Time: 188.95s\n",
      "Epoch 2/15, Train Loss: 0.4690, Train Acc: 82.40%, Val Loss: 0.5011, Val Acc: 80.69%, Time: 189.17s\n",
      "Epoch 3/15, Train Loss: 0.3639, Train Acc: 86.58%, Val Loss: 0.5146, Val Acc: 81.06%, Time: 189.20s\n",
      "Epoch 4/15, Train Loss: 0.2607, Train Acc: 90.75%, Val Loss: 0.5765, Val Acc: 78.51%, Time: 189.32s\n",
      "Epoch 5/15, Train Loss: 0.1872, Train Acc: 93.84%, Val Loss: 0.6645, Val Acc: 79.60%, Time: 190.38s\n",
      "Epoch 6/15, Train Loss: 0.1396, Train Acc: 95.16%, Val Loss: 0.7104, Val Acc: 81.06%, Time: 189.21s\n",
      "Epoch 7/15, Train Loss: 0.0867, Train Acc: 97.35%, Val Loss: 0.7513, Val Acc: 80.33%, Time: 189.20s\n",
      "Epoch 8/15, Train Loss: 0.0717, Train Acc: 98.05%, Val Loss: 0.7590, Val Acc: 83.61%, Time: 189.54s\n",
      "Epoch 9/15, Train Loss: 0.0697, Train Acc: 98.48%, Val Loss: 0.7291, Val Acc: 82.70%, Time: 189.85s\n",
      "Epoch 10/15, Train Loss: 0.0466, Train Acc: 98.44%, Val Loss: 0.8032, Val Acc: 81.60%, Time: 189.72s\n",
      "Epoch 11/15, Train Loss: 0.0455, Train Acc: 98.67%, Val Loss: 0.7842, Val Acc: 82.33%, Time: 189.75s\n",
      "Epoch 12/15, Train Loss: 0.0363, Train Acc: 98.75%, Val Loss: 0.7559, Val Acc: 83.61%, Time: 188.84s\n",
      "Epoch 13/15, Train Loss: 0.0397, Train Acc: 98.63%, Val Loss: 0.7814, Val Acc: 83.42%, Time: 188.38s\n",
      "Epoch 14/15, Train Loss: 0.0266, Train Acc: 98.95%, Val Loss: 0.8056, Val Acc: 83.42%, Time: 189.67s\n",
      "Epoch 15/15, Train Loss: 0.0322, Train Acc: 98.83%, Val Loss: 0.8380, Val Acc: 84.15%, Time: 189.59s\n",
      "Training completed in 2840.78 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadu\\AppData\\Local\\Temp\\ipykernel_31996\\1168244988.py:304: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.model.load_state_dict(torch.load('best_efficientnet_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7255, Test Accuracy: 84.00%\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           No DR       0.97      1.00      0.99       274\n",
      "         Mild DR       0.78      0.51      0.61        69\n",
      "     Moderate DR       0.70      0.87      0.78       142\n",
      "       Severe DR       0.54      0.56      0.55        27\n",
      "Proliferative DR       0.71      0.39      0.51        38\n",
      "\n",
      "        accuracy                           0.84       550\n",
      "       macro avg       0.74      0.67      0.69       550\n",
      "    weighted avg       0.84      0.84      0.83       550\n",
      "\n",
      "Best validation accuracy: 84.15%\n",
      "Final test accuracy: 84.00%\n",
      "Model saved as 'best_efficientnet_model.pth'\n",
      "Training curves saved as 'training_curves.png'\n",
      "Confusion matrix saved as 'confusion_matrix.png'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            img_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform if transform is not None else transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.data_frame.iloc[idx]['id_code'] + '.png')\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        diagnosis = self.data_frame.iloc[idx]['diagnosis']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(diagnosis, dtype=torch.long)\n",
    "\n",
    "class RetinalEfficientNetClassifier:\n",
    "    def __init__(self, num_classes=5, model_name='efficientnet_b0'):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load pre-trained EfficientNet\n",
    "        if model_name == 'efficientnet_b0':\n",
    "            self.model = models.efficientnet_b0(weights='DEFAULT')\n",
    "        elif model_name == 'efficientnet_b1':\n",
    "            self.model = models.efficientnet_b1(weights='DEFAULT')\n",
    "        elif model_name == 'efficientnet_b2':\n",
    "            self.model = models.efficientnet_b2(weights='DEFAULT')\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_features = self.model.classifier[1].in_features\n",
    "        self.model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Move model to device\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Define transformation pipeline\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Track metrics\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def train(self, train_loader, val_loader=None, num_epochs=10, learning_rate=0.0001):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "        \n",
    "        best_val_accuracy = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            # Training phase\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_accuracy = 100 * correct / total\n",
    "            self.train_losses.append(epoch_loss)\n",
    "            self.train_accuracies.append(epoch_accuracy)\n",
    "            \n",
    "            # Validation phase\n",
    "            if val_loader:\n",
    "                val_loss, val_accuracy = self.evaluate(val_loader, criterion)\n",
    "                self.val_losses.append(val_loss)\n",
    "                self.val_accuracies.append(val_accuracy)\n",
    "                \n",
    "                # Save best model\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    torch.save(self.model.state_dict(), 'best_efficientnet_model.pth')\n",
    "                \n",
    "                epoch_time = time.time() - epoch_start\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "                      f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_accuracy:.2f}%, '\n",
    "                      f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, '\n",
    "                      f'Time: {epoch_time:.2f}s')\n",
    "            else:\n",
    "                epoch_time = time.time() - epoch_start\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "                      f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_accuracy:.2f}%, '\n",
    "                      f'Time: {epoch_time:.2f}s')\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f'Training completed in {total_time:.2f} seconds')\n",
    "        \n",
    "        # Plot training curves\n",
    "        if len(self.train_losses) > 1:\n",
    "            self.plot_training_curves()\n",
    "            \n",
    "        \n",
    "        return best_val_accuracy\n",
    "\n",
    "    def evaluate(self, test_loader, criterion=None):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        if criterion is None:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        test_loss = running_loss / len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        \n",
    "        return test_loss, test_accuracy\n",
    "    \n",
    "    def get_all_predictions(self, data_loader):\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "        \n",
    "        return np.array(all_predictions), np.array(all_labels)\n",
    "    \n",
    "    def plot_confusion_matrix(self, test_loader, class_names=None):\n",
    "        predictions, true_labels = self.get_all_predictions(test_loader)\n",
    "        cm = confusion_matrix(true_labels, predictions)\n",
    "        \n",
    "        if class_names is None:\n",
    "            class_names = [str(i) for i in range(cm.shape[0])]\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(classification_report(true_labels, predictions, target_names=class_names))\n",
    "\n",
    "    def plot_training_curves(self):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Train Loss')\n",
    "        if self.val_losses:\n",
    "            plt.plot(self.val_losses, label='Validation Loss')\n",
    "        plt.title('Loss Curves')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.train_accuracies, label='Train Accuracy')\n",
    "        if self.val_accuracies:\n",
    "            plt.plot(self.val_accuracies, label='Validation Accuracy')\n",
    "        plt.title('Accuracy Curves')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_curves.png')\n",
    "        plt.close()\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        self.model.eval()\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "        return predicted.item()\n",
    "\n",
    "# Run experiment\n",
    "if __name__ == \"__main__\":\n",
    "    # Define data augmentation for training\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Simple transforms for validation/test\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    full_dataset = RetinalDataset(\n",
    "        csv_file='train.csv', \n",
    "        img_dir='train_images',\n",
    "        transform=None  # We'll apply transforms separately to each split\n",
    "    )\n",
    "\n",
    "    # Split dataset (70% train, 15% validation, 15% test)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    val_size = int(0.15 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset, [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    # Apply appropriate transforms to each dataset\n",
    "    train_dataset.dataset.transform = train_transform\n",
    "    val_dataset.dataset.transform = test_transform\n",
    "    test_dataset.dataset.transform = test_transform\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Set class names\n",
    "    class_names = ['No DR', 'Mild DR', 'Moderate DR', 'Severe DR', 'Proliferative DR']\n",
    "\n",
    "    # Initialize and train the classifier\n",
    "    classifier = RetinalEfficientNetClassifier(num_classes=5, model_name='efficientnet_b0')\n",
    "    \n",
    "    # Train the model\n",
    "    best_val_accuracy = classifier.train(train_loader, val_loader, num_epochs=15, learning_rate=3e-4)\n",
    "    \n",
    "    # Load best model\n",
    "    classifier.model.load_state_dict(torch.load('best_efficientnet_model.pth'))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = classifier.evaluate(test_loader)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    classifier.plot_confusion_matrix(test_loader, class_names)\n",
    "    \n",
    "    print(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "    print(f\"Final test accuracy: {test_accuracy:.2f}%\")\n",
    "    print(\"Model saved as 'best_efficientnet_model.pth'\")\n",
    "    print(\"Training curves saved as 'training_curves.png'\")\n",
    "    print(\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
