{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=4):  # 4 classes: background, haemorrhages, hard exudates, microaneurysm\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Encoder\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(64, 128)\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(128, 256)\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(256, 512)\n",
    "        )\n",
    "        self.down4 = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(512, 1024)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.up_conv1 = DoubleConv(1024, 512)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up_conv2 = DoubleConv(512, 256)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up_conv3 = DoubleConv(256, 128)\n",
    "        \n",
    "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up_conv4 = DoubleConv(128, 64)\n",
    "        \n",
    "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x5)\n",
    "        x = torch.cat([x4, x], dim=1)\n",
    "        x = self.up_conv1(x)\n",
    "        \n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x3, x], dim=1)\n",
    "        x = self.up_conv2(x)\n",
    "        \n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "        x = self.up_conv3(x)\n",
    "        \n",
    "        x = self.up4(x)\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "        x = self.up_conv4(x)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "class RetinalMultiClassDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_dir, \n",
    "                 haemorrhages_mask_dir, \n",
    "                 hard_exudates_mask_dir, \n",
    "                 microaneurysm_mask_dir,\n",
    "                 transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.haemorrhages_mask_dir = Path(haemorrhages_mask_dir)\n",
    "        self.hard_exudates_mask_dir = Path(hard_exudates_mask_dir)\n",
    "        self.microaneurysm_mask_dir = Path(microaneurysm_mask_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get list of image files\n",
    "        self.images = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = str(self.image_dir / img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load individual masks\n",
    "        # Assuming mask filenames match image filenames\n",
    "        haemorrhage_mask_path = str(self.haemorrhages_mask_dir / img_name)\n",
    "        hard_exudate_mask_path = str(self.hard_exudates_mask_dir / img_name)\n",
    "        microaneurysm_mask_path = str(self.microaneurysm_mask_dir / img_name)\n",
    "        \n",
    "        haemorrhage_mask = Image.open(haemorrhage_mask_path).convert('L')\n",
    "        hard_exudate_mask = Image.open(hard_exudate_mask_path).convert('L')\n",
    "        microaneurysm_mask = Image.open(microaneurysm_mask_path).convert('L')\n",
    "        \n",
    "        # Apply transforms to image and masks\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        image = transform(image)\n",
    "        \n",
    "        # Transform masks and convert to binary (0 or 1)\n",
    "        haemorrhage_mask = transform(haemorrhage_mask) > 0.5\n",
    "        hard_exudate_mask = transform(hard_exudate_mask) > 0.5\n",
    "        microaneurysm_mask = transform(microaneurysm_mask) > 0.5\n",
    "        \n",
    "        # Create a multi-class mask where:\n",
    "        # 0: Background\n",
    "        # 1: Haemorrhages\n",
    "        # 2: Hard Exudates\n",
    "        # 3: Microaneurysms\n",
    "        multi_class_mask = torch.zeros((1, 256, 256), dtype=torch.long)\n",
    "        \n",
    "        # Set the values for each class\n",
    "        # Priority: if pixels belong to multiple classes, choose one based on priority\n",
    "        multi_class_mask[haemorrhage_mask] = 1\n",
    "        multi_class_mask[hard_exudate_mask] = 2\n",
    "        multi_class_mask[microaneurysm_mask] = 3\n",
    "        \n",
    "        return image, multi_class_mask.squeeze(0)\n",
    "\n",
    "class RetinalSegmentation:\n",
    "    def __init__(self, n_classes=4):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else \n",
    "                                  'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "        self.model = UNet(n_channels=3, n_classes=n_classes).to(self.device)\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def train(self, train_loader, num_epochs=10):\n",
    "        # Use Cross Entropy Loss for multi-class segmentation\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "        print(f\"Training on {self.device}\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for images, masks in train_loader:\n",
    "                images = images.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)  # [B, C, H, W]\n",
    "                \n",
    "                loss = criterion(outputs, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
    "            \n",
    "            # Validate after each epoch\n",
    "            if epoch % 2 == 0:\n",
    "                self.evaluate_sample(train_loader)\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"Generate prediction for a single image\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            image = image.to(self.device)\n",
    "            output = self.model(image.unsqueeze(0))\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            predicted_mask = torch.argmax(probabilities, dim=1)\n",
    "            return predicted_mask.squeeze().cpu().numpy()\n",
    "    \n",
    "    def evaluate_sample(self, dataloader):\n",
    "        \"\"\"Visualize prediction on a sample from the dataset\"\"\"\n",
    "        # Get a sample\n",
    "        images, masks = next(iter(dataloader))\n",
    "        image = images[0].to(self.device)\n",
    "        mask = masks[0].cpu().numpy()\n",
    "        \n",
    "        # Generate prediction\n",
    "        pred_mask = self.predict(image)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Original image\n",
    "        axs[0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        axs[0].set_title('Original Image')\n",
    "        axs[0].axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        colors = ['black', 'red', 'yellow', 'green']  # colors for different classes\n",
    "        cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "        axs[1].imshow(mask, cmap=cmap, vmin=0, vmax=3)\n",
    "        axs[1].set_title('Ground Truth')\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "        # Predicted mask\n",
    "        axs[2].imshow(pred_mask, cmap=cmap, vmin=0, vmax=3)\n",
    "        axs[2].set_title('Prediction')\n",
    "        axs[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    dataset = RetinalMultiClassDataset(\n",
    "        image_dir='path/to/images',\n",
    "        haemorrhages_mask_dir='path/to/haemorrhages_masks',\n",
    "        hard_exudates_mask_dir='path/to/hard_exudates_masks',\n",
    "        microaneurysm_mask_dir='path/to/microaneurysm_masks'\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    segmentation = RetinalSegmentation(n_classes=4)\n",
    "    segmentation.train(train_loader, num_epochs=20)\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(segmentation.model.state_dict(), 'retinal_segmentation_model.pth')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
