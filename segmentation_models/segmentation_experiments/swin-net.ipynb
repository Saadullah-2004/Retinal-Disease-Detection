{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Print CUDA information at the start\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "# -------------------------\n",
    "# Swin Transformer Block\n",
    "# -------------------------\n",
    "# A simplified transformer block that mimics a Swin block\n",
    "# (Note: This version uses global attention rather than window-based attention.)\n",
    "class SwinTransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads):\n",
    "        super(SwinTransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * 4, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W) --> reshape to (B, N, C) where N = H*W\n",
    "        B, C, H, W = x.shape\n",
    "        x_flat = x.view(B, C, H * W).permute(0, 2, 1)  # (B, N, C)\n",
    "        x_norm = self.norm1(x_flat)\n",
    "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
    "        x_flat = x_flat + attn_out  # residual connection\n",
    "        x_norm2 = self.norm2(x_flat)\n",
    "        mlp_out = self.mlp(x_norm2)\n",
    "        x_flat = x_flat + mlp_out   # residual connection\n",
    "        # Reshape back to (B, C, H, W)\n",
    "        x_out = x_flat.permute(0, 2, 1).view(B, C, H, W)\n",
    "        return x_out\n",
    "\n",
    "# -------------------------\n",
    "# SwinNet Architecture\n",
    "# -------------------------\n",
    "# A U-Net style architecture where the encoder uses a patch embedding\n",
    "# and several SwinTransformerBlocks, with a decoder that upsamples and\n",
    "# uses skip connections.\n",
    "class SwinUnet(nn.Module):\n",
    "    def __init__(self, img_size=256, patch_size=4, in_chans=3, num_classes=4, embed_dim=96):\n",
    "        super(SwinUnet, self).__init__()\n",
    "        # Patch embedding (downsamples by patch_size)\n",
    "        self.patch_embed = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        # Encoder stage 1\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            SwinTransformerBlock(embed_dim, num_heads=3),\n",
    "            SwinTransformerBlock(embed_dim, num_heads=3)\n",
    "        )\n",
    "        self.down1 = nn.Conv2d(embed_dim, embed_dim * 2, kernel_size=2, stride=2)\n",
    "        # Encoder stage 2\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            SwinTransformerBlock(embed_dim * 2, num_heads=6),\n",
    "            SwinTransformerBlock(embed_dim * 2, num_heads=6)\n",
    "        )\n",
    "        self.down2 = nn.Conv2d(embed_dim * 2, embed_dim * 4, kernel_size=2, stride=2)\n",
    "        # Encoder stage 3\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            SwinTransformerBlock(embed_dim * 4, num_heads=12),\n",
    "            SwinTransformerBlock(embed_dim * 4, num_heads=12)\n",
    "        )\n",
    "        self.down3 = nn.Conv2d(embed_dim * 4, embed_dim * 8, kernel_size=2, stride=2)\n",
    "        # Bottleneck (Encoder stage 4)\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            SwinTransformerBlock(embed_dim * 8, num_heads=24),\n",
    "            SwinTransformerBlock(embed_dim * 8, num_heads=24)\n",
    "        )\n",
    "        # Decoder stage 3\n",
    "        self.up3 = nn.ConvTranspose2d(embed_dim * 8, embed_dim * 4, kernel_size=2, stride=2)\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Conv2d(embed_dim * 8, embed_dim * 4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(embed_dim * 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Decoder stage 2\n",
    "        self.up2 = nn.ConvTranspose2d(embed_dim * 4, embed_dim * 2, kernel_size=2, stride=2)\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Conv2d(embed_dim * 4, embed_dim * 2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(embed_dim * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Decoder stage 1\n",
    "        self.up1 = nn.ConvTranspose2d(embed_dim * 2, embed_dim, kernel_size=2, stride=2)\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Conv2d(embed_dim * 2, embed_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(embed_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.out_conv = nn.Conv2d(embed_dim, num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x0 = self.patch_embed(x)  # [B, embed_dim, 256/patch_size, 256/patch_size]\n",
    "        e1 = self.encoder1(x0)      # skip connection 1\n",
    "        x1 = self.down1(e1)         # downsample to [B, embed_dim*2, ...]\n",
    "        e2 = self.encoder2(x1)      # skip connection 2\n",
    "        x2 = self.down2(e2)         # downsample to [B, embed_dim*4, ...]\n",
    "        e3 = self.encoder3(x2)      # skip connection 3\n",
    "        x3 = self.down3(e3)         # downsample to [B, embed_dim*8, ...]\n",
    "        e4 = self.encoder4(x3)      # bottleneck\n",
    "        \n",
    "        # Decoder\n",
    "        d3 = self.up3(e4)           # upsample to match e3 spatial size\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "        d2 = self.up2(d3)           # upsample to match e2 spatial size\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "        d1 = self.up1(d2)           # upsample to match e1 spatial size\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "        out = self.out_conv(d1)\n",
    "        return out\n",
    "\n",
    "# -------------------------\n",
    "# Dataset Definition\n",
    "# -------------------------\n",
    "class RetinalMultiClassDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 image_dir, \n",
    "                 haemorrhages_mask_dir, \n",
    "                 hard_exudates_mask_dir, \n",
    "                 microaneurysm_mask_dir,\n",
    "                 transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.haemorrhages_mask_dir = Path(haemorrhages_mask_dir)\n",
    "        self.hard_exudates_mask_dir = Path(hard_exudates_mask_dir)\n",
    "        self.microaneurysm_mask_dir = Path(microaneurysm_mask_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        for dir_path in [self.image_dir, self.haemorrhages_mask_dir, \n",
    "                         self.hard_exudates_mask_dir, self.microaneurysm_mask_dir]:\n",
    "            if not dir_path.exists():\n",
    "                print(f\"WARNING: Directory does not exist: {dir_path}\")\n",
    "                print(f\"Current working directory: {os.getcwd()}\")\n",
    "                print(f\"Available directories: {os.listdir('.')}\")\n",
    "        \n",
    "        try:\n",
    "            self.images = sorted([f for f in os.listdir(image_dir) \n",
    "                                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            print(f\"Found {len(self.images)} images in {image_dir}\")\n",
    "            if len(self.images) == 0:\n",
    "                print(f\"WARNING: No images found in {image_dir}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Directory not found: {image_dir}\")\n",
    "            self.images = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = self.images[idx]\n",
    "            img_path = str(self.image_dir / img_name)\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"WARNING: Image not found: {img_path}\")\n",
    "                return torch.zeros((3, 256, 256)), torch.zeros((256, 256), dtype=torch.long)\n",
    "            \n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            # Load masks (assumes filenames match)\n",
    "            haemorrhage_mask_path = str(self.haemorrhages_mask_dir / img_name)\n",
    "            hard_exudate_mask_path = str(self.hard_exudates_mask_dir / img_name)\n",
    "            microaneurysm_mask_path = str(self.microaneurysm_mask_dir / img_name)\n",
    "            \n",
    "            if not os.path.exists(haemorrhage_mask_path):\n",
    "                print(f\"WARNING: Haemorrhage mask not found: {haemorrhage_mask_path}\")\n",
    "                haemorrhage_mask = Image.new('L', image.size, 0)\n",
    "            else:\n",
    "                haemorrhage_mask = Image.open(haemorrhage_mask_path).convert('L')\n",
    "            \n",
    "            if not os.path.exists(hard_exudate_mask_path):\n",
    "                print(f\"WARNING: Hard exudate mask not found: {hard_exudate_mask_path}\")\n",
    "                hard_exudate_mask = Image.new('L', image.size, 0)\n",
    "            else:\n",
    "                hard_exudate_mask = Image.open(hard_exudate_mask_path).convert('L')\n",
    "            \n",
    "            if not os.path.exists(microaneurysm_mask_path):\n",
    "                print(f\"WARNING: Microaneurysm mask not found: {microaneurysm_mask_path}\")\n",
    "                microaneurysm_mask = Image.new('L', image.size, 0)\n",
    "            else:\n",
    "                microaneurysm_mask = Image.open(microaneurysm_mask_path).convert('L')\n",
    "            \n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "            image = transform(image)\n",
    "            haemorrhage_mask = transform(haemorrhage_mask) > 0.5\n",
    "            hard_exudate_mask = transform(hard_exudate_mask) > 0.5\n",
    "            microaneurysm_mask = transform(microaneurysm_mask) > 0.5\n",
    "            \n",
    "            multi_class_mask = torch.zeros((1, 256, 256), dtype=torch.long)\n",
    "            multi_class_mask[haemorrhage_mask] = 1\n",
    "            multi_class_mask[hard_exudate_mask] = 2\n",
    "            multi_class_mask[microaneurysm_mask] = 3\n",
    "            \n",
    "            return image, multi_class_mask.squeeze(0)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in __getitem__ for index {idx}, image {self.images[idx] if idx < len(self.images) else 'invalid index'}: {str(e)}\")\n",
    "            return torch.zeros((3, 256, 256)), torch.zeros((256, 256), dtype=torch.long)\n",
    "\n",
    "# -------------------------\n",
    "# Segmentation Training Class\n",
    "# -------------------------\n",
    "# Uses CrossEntropyLoss for multi-class segmentation.\n",
    "class RetinalSegmentation:\n",
    "    def __init__(self, n_classes=4):\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                self.device = torch.device('cuda')\n",
    "                test_tensor = torch.zeros(1, device=self.device)\n",
    "                del test_tensor\n",
    "                print(\"Successfully initialized CUDA device\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"CUDA error: {e}\")\n",
    "                print(\"Falling back to CPU\")\n",
    "                self.device = torch.device('cpu')\n",
    "        elif torch.backends.mps.is_available():\n",
    "            try:\n",
    "                self.device = torch.device('mps')\n",
    "                print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "            except Exception:\n",
    "                print(\"MPS initialization failed, falling back to CPU\")\n",
    "                self.device = torch.device('cpu')\n",
    "        else:\n",
    "            self.device = torch.device('cpu')\n",
    "            print(\"Using CPU device\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize the SwinUnet model\n",
    "            self.model = SwinUnet(img_size=256, patch_size=4, in_chans=3, num_classes=n_classes, embed_dim=96).to(self.device)\n",
    "            print(f\"Model initialized and moved to {self.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing model: {e}\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "    def train(self, train_loader, num_epochs=10):\n",
    "        if len(train_loader) == 0:\n",
    "            print(\"ERROR: DataLoader is empty. Cannot train on empty dataset.\")\n",
    "            return\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "        print(f\"Training on {self.device}\")\n",
    "        print(f\"Training with {len(train_loader)} batches per epoch\")\n",
    "        \n",
    "        epoch_losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            start_time = time.time()\n",
    "            print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "                if batch_idx % 5 == 0:\n",
    "                    print(f\"  Processing batch {batch_idx+1}/{len(train_loader)}\")\n",
    "                try:\n",
    "                    images = images.to(self.device)\n",
    "                    masks = masks.to(self.device)\n",
    "                    \n",
    "                    if torch.isnan(images).any() or torch.isnan(masks).any():\n",
    "                        print(f\"WARNING: NaN values detected in input data (batch {batch_idx+1})\")\n",
    "                        continue\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = self.model(images)\n",
    "                    if batch_idx == 0 and epoch == 0:\n",
    "                        print(f\"Input shape: {images.shape}\")\n",
    "                        print(f\"Output shape: {outputs.shape}\")\n",
    "                        print(f\"Target shape: {masks.shape}\")\n",
    "                    \n",
    "                    loss = criterion(outputs, masks)\n",
    "                    if torch.isnan(loss):\n",
    "                        print(f\"WARNING: NaN loss detected in batch {batch_idx+1}\")\n",
    "                        continue\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    running_loss += loss.item()\n",
    "                    \n",
    "                    if self.device.type == 'cuda':\n",
    "                        torch.cuda.synchronize()\n",
    "                except Exception as e:\n",
    "                    print(f\"ERROR in training loop (batch {batch_idx+1}): {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            epoch_losses.append(avg_loss)\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
    "            \n",
    "            if epoch % 2 == 0:\n",
    "                try:\n",
    "                    self.evaluate_sample(train_loader)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in evaluation: {e}\")\n",
    "        \n",
    "        try:\n",
    "            plt.figure()\n",
    "            plt.plot(range(1, num_epochs + 1), epoch_losses, marker='o')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('Training Loss Over Epochs')\n",
    "            plt.grid(True)\n",
    "            plt.savefig('training_loss.png')\n",
    "            print(\"Training loss plot saved to 'training_loss.png'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting training loss: {e}\")\n",
    "    \n",
    "    def predict(self, image):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                image = image.to(self.device)\n",
    "                output = self.model(image.unsqueeze(0))\n",
    "                probabilities = F.softmax(output, dim=1)\n",
    "                predicted_mask = torch.argmax(probabilities, dim=1)\n",
    "                return predicted_mask.squeeze().cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in prediction: {e}\")\n",
    "                return np.zeros((256, 256), dtype=np.int64)\n",
    "    \n",
    "    def evaluate_sample(self, dataloader):\n",
    "        try:\n",
    "            images, masks = next(iter(dataloader))\n",
    "            image = images[0].to(self.device)\n",
    "            mask = masks[0].cpu().numpy()\n",
    "            pred_mask = self.predict(image)\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            axs[0].imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "            axs[0].set_title('Original Image')\n",
    "            axs[0].axis('off')\n",
    "            colors = ['black', 'red', 'yellow', 'green']\n",
    "            cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "            axs[1].imshow(mask, cmap=cmap, vmin=0, vmax=3)\n",
    "            axs[1].set_title('Ground Truth')\n",
    "            axs[1].axis('off')\n",
    "            axs[2].imshow(pred_mask, cmap=cmap, vmin=0, vmax=3)\n",
    "            axs[2].set_title('Prediction')\n",
    "            axs[2].axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"sample_evaluation_{time.strftime('%Y%m%d_%H%M%S')}.png\")\n",
    "            print(\"Evaluation sample saved as image file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in evaluation: {e}\")\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Starting retinal segmentation training script using SwinNet architecture\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Update these directory paths to match your actual data locations.\n",
    "    image_dir = 'C:/Second_Sem/490/train_images'\n",
    "    haemorrhages_mask_dir = 'C:/Second_Sem/490/APTOS 2019 Blindness Detection Segmented/Haemorrhages/train_images'\n",
    "    hard_exudates_mask_dir = 'C:/Second_Sem/490/APTOS 2019 Blindness Detection Segmented/Hard Exudates/train_images'\n",
    "    microaneurysm_mask_dir = 'C:/Second_Sem/490/APTOS 2019 Blindness Detection Segmented/Microaneurysm/train_images'\n",
    "    \n",
    "    for dir_path in [image_dir, haemorrhages_mask_dir, hard_exudates_mask_dir, microaneurysm_mask_dir]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            print(f\"WARNING: Directory does not exist: {dir_path}\")\n",
    "    \n",
    "    print(\"Creating dataset...\")\n",
    "    dataset = RetinalMultiClassDataset(\n",
    "        image_dir=image_dir,\n",
    "        haemorrhages_mask_dir=haemorrhages_mask_dir,\n",
    "        hard_exudates_mask_dir=hard_exudates_mask_dir,\n",
    "        microaneurysm_mask_dir=microaneurysm_mask_dir\n",
    "    )\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(\"ERROR: Dataset is empty. Please check your directory paths and image files.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Dataset created with {len(dataset)} samples\")\n",
    "    print(\"Verifying dataset by loading first sample...\")\n",
    "    try:\n",
    "        sample_img, sample_mask = dataset[0]\n",
    "        print(f\"Sample image shape: {sample_img.shape}\")\n",
    "        print(f\"Sample mask shape: {sample_mask.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load sample from dataset: {e}\")\n",
    "    \n",
    "    print(\"Creating data loader...\")\n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Set to >0 for production runs\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    print(\"Initializing segmentation model...\")\n",
    "    segmentation = RetinalSegmentation(n_classes=4)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    segmentation.train(train_loader, num_epochs=20)\n",
    "    \n",
    "    try:\n",
    "        torch.save(segmentation.model.state_dict(), 'retinal_segmentation_model_swin.pth')\n",
    "        print(\"Model saved successfully to 'retinal_segmentation_model_swin.pth'\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to save model: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training completed\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"Unhandled exception in main: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
