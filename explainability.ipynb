{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([5, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 214\u001b[0m\n\u001b[1;32m    211\u001b[0m explainer \u001b[38;5;241m=\u001b[39m RetinalExplainer(model)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Generate and display explanation for a sample image\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/devshah/Documents/WorkSpace/University/year 3/CSC490/Zero-Shot-Object-Tracking-FPS/APTOS 2019 Blindness Detection/train_images/0a4e1a29ffff.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[9], line 112\u001b[0m, in \u001b[0;36mRetinalExplainer.plot_explanation\u001b[0;34m(self, image_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03mPlot the original image, heatmap, and superimposed visualization\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Generate explanation\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m superimposed_img, pred_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Load original image\u001b[39;00m\n\u001b[1;32m    115\u001b[0m original_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n",
      "Cell \u001b[0;32mIn[9], line 90\u001b[0m, in \u001b[0;36mRetinalExplainer.explain\u001b[0;34m(self, image_path, save_path)\u001b[0m\n\u001b[1;32m     87\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m preprocess(image)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Generate CAM\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m cam, pred_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_cam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_cam\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Convert CAM to heatmap\u001b[39;00m\n\u001b[1;32m     93\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mapplyColorMap(np\u001b[38;5;241m.\u001b[39muint8(\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m cam), cv2\u001b[38;5;241m.\u001b[39mCOLORMAP_JET)\n",
      "Cell \u001b[0;32mIn[9], line 61\u001b[0m, in \u001b[0;36mGradCAM.generate_cam\u001b[0;34m(self, input_image, target_class)\u001b[0m\n\u001b[1;32m     58\u001b[0m cam \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(activations, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [196]\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Reshape to square\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m width \u001b[38;5;241m=\u001b[39m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mmath\u001b[49m\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m196\u001b[39m))  \u001b[38;5;66;03m# 14x14\u001b[39;00m\n\u001b[1;32m     62\u001b[0m cam \u001b[38;5;241m=\u001b[39m cam\u001b[38;5;241m.\u001b[39mview(width, height)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# ReLU and normalize\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from transformers import ViTForImageClassification\n",
    "from torchvision import transforms\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model.model\n",
    "        self.target_layer = self.model.vit.encoder.layer[-1].output  # Last encoder block\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        \n",
    "        def save_gradient(grad):\n",
    "            \"\"\"Hook to capture gradients during backpropagation\"\"\"\n",
    "            self.gradients.append(grad.detach())\n",
    "\n",
    "        def save_activation(module, input, output):\n",
    "            \"\"\"Hook to capture activations during forward pass\"\"\"\n",
    "            self.activations.append(output.detach())\n",
    "            output.register_hook(save_gradient)  # Register hook on the output tensor\n",
    "        \n",
    "        # Register hooks\n",
    "        self.target_layer.register_forward_hook(save_activation)\n",
    "\n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        \n",
    "        image_tensor = input_image.unsqueeze(0).to(self.model.device)\n",
    "\n",
    "        self.model.train()  # ‚úÖ Enable train mode for correct backprop behavior\n",
    "\n",
    "        # Forward pass\n",
    "        output = self.model(image_tensor).logits\n",
    "        pred_class = output.argmax(dim=1).item() if target_class is None else target_class\n",
    "\n",
    "        # Clear gradients\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        class_loss = output[0, pred_class]\n",
    "        class_loss.backward()\n",
    "\n",
    "        self.model.eval()  # ‚úÖ Restore eval mode\n",
    "\n",
    "        # Ensure gradients are non-zero\n",
    "        gradients = self.gradients[0] if self.gradients else None\n",
    "        if gradients is None or torch.all(gradients == 0):\n",
    "            print(\"üö® Gradients are still zero! Check target layer selection or backprop.\")\n",
    "            return None, pred_class\n",
    "        else:\n",
    "            print(f\"‚úÖ Non-zero gradients found! {gradients.shape}\")\n",
    "\n",
    "        # Get activations and gradients\n",
    "        gradients = self.gradients[0]  # [1, 197, 768]\n",
    "        activations = self.activations[0]  # [1, 197, 768]\n",
    "\n",
    "        # Remove CLS token\n",
    "        gradients = gradients[:, 1:, :]  # [1, 196, 768]\n",
    "        activations = activations[:, 1:, :]  # [1, 196, 768]\n",
    "\n",
    "        # Pool the gradients\n",
    "        pooled_gradients = torch.mean(gradients, dim=[0, 1])  # [768]\n",
    "\n",
    "        # Weight activations by importance scores\n",
    "        for i in range(768):\n",
    "            activations[:, :, i] *= pooled_gradients[i]\n",
    "\n",
    "        # Average over the feature dimension\n",
    "        cam = torch.mean(activations, dim=2).squeeze(0)  # [196]\n",
    "\n",
    "        # Reshape to square (14x14)\n",
    "        cam = cam.view(14, 14)\n",
    "\n",
    "        # Normalize CAM\n",
    "        cam = torch.maximum(cam, torch.tensor(0, device=self.model.device))\n",
    "        if cam.max() != 0:\n",
    "            cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "\n",
    "        # Resize to match input image\n",
    "        cam = cam.cpu().numpy()\n",
    "        cam = cv2.resize(cam, (input_image.shape[2], input_image.shape[1]))\n",
    "\n",
    "        print(f\"‚úÖ Grad-CAM Successfully Generated for Class: {pred_class}\")\n",
    "\n",
    "        return cam, pred_class\n",
    "\n",
    "\n",
    "class RetinalClassifier:\n",
    "    def __init__(self, num_classes=5):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load pre-trained model while ignoring classifier size mismatch\n",
    "        self.model = ViTForImageClassification.from_pretrained(\n",
    "            'google/vit-base-patch16-224',\n",
    "            num_labels=num_classes,\n",
    "            ignore_mismatched_sizes=True  # Prevents classifier size errors\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Replace classifier layer\n",
    "        self.model.classifier = torch.nn.Linear(self.model.config.hidden_size, num_classes).to(self.device)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        self.model.eval()\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image).logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "        return predicted.item()\n",
    "\n",
    "\n",
    "class RetinalExplainer:\n",
    "    def __init__(self, classifier_model):\n",
    "        self.grad_cam = GradCAM(classifier_model)\n",
    "        self.model = classifier_model\n",
    "        \n",
    "    def explain(self, image_path, save_path=None):\n",
    "        \"\"\"Generate and optionally save explanation visualization\"\"\"\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        preprocess = self.model.transform\n",
    "        input_tensor = preprocess(image).to(self.model.model.device)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam, pred_class = self.grad_cam.generate_cam(input_tensor)\n",
    "        if cam is None:\n",
    "            return None, pred_class\n",
    "        \n",
    "        # Convert CAM to heatmap\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Load original image and resize to match heatmap\n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image = cv2.resize(original_image, (cam.shape[1], cam.shape[0]))\n",
    "        \n",
    "        # Superimpose heatmap on original image\n",
    "        superimposed_img = cv2.addWeighted(original_image, 0.7, heatmap, 0.3, 0)\n",
    "        \n",
    "        if save_path:\n",
    "            cv2.imwrite(save_path, superimposed_img)\n",
    "            \n",
    "        return superimposed_img, pred_class\n",
    "\n",
    "    def plot_explanation(self, image_path):\n",
    "        \"\"\"Plot original image, heatmap, and superimposed visualization\"\"\"\n",
    "        superimposed_img, pred_class = self.explain(image_path)\n",
    "        if superimposed_img is None:\n",
    "            print(\"‚ùå Grad-CAM generation failed due to zero gradients.\")\n",
    "            return None\n",
    "\n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Plot original image\n",
    "        ax1.imshow(original_image)\n",
    "        ax1.set_title('Original Image')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Plot Grad-CAM visualization\n",
    "        ax2.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title(f'Grad-CAM Visualization\\nPredicted Class: {pred_class}')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "\n",
    "# ‚úÖ Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    model = RetinalClassifier()\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint = torch.load('best_model.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "    # Remove classifier from checkpoint\n",
    "    filtered_checkpoint = {k: v for k, v in checkpoint['model_state_dict'].items() if not k.startswith(\"classifier\")}\n",
    "    model.model.load_state_dict(filtered_checkpoint, strict=False)\n",
    "\n",
    "    print(\"Checkpoint loaded successfully, classifier initialized randomly.\")\n",
    "\n",
    "    explainer = RetinalExplainer(model)\n",
    "    \n",
    "    # Generate explanation for an image\n",
    "    fig = explainer.plot_explanation('/Users/tanishroy/Desktop/School/Third year/Retinal-Disease-Detection-main/APTOS 2019 Blindness Detection Segmented/train_images/0a4e1a29ffff.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
