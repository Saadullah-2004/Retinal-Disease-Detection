{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.feature_extractor = model.vit\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get the attention blocks\n",
    "        self.target_layers = [self.feature_extractor.encoder.layer[-1].attention]\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        \n",
    "        def save_gradient(grad):\n",
    "            self.gradients.append(grad)\n",
    "            \n",
    "        def save_activation(module, input, output):\n",
    "            self.activations.append(output)\n",
    "            \n",
    "        # Register hooks\n",
    "        for layer in self.target_layers:\n",
    "            layer.register_forward_hook(save_activation)\n",
    "            layer.register_backward_hook(save_gradient)\n",
    "\n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "        \"\"\"\n",
    "        Generate Grad-CAM visualization for the input image\n",
    "        \n",
    "        Args:\n",
    "            input_image: preprocessed image tensor\n",
    "            target_class: class index for which to generate CAM (if None, uses predicted class)\n",
    "        \n",
    "        Returns:\n",
    "            cam: numpy array of the same size as input image\n",
    "            pred_class: predicted class index\n",
    "        \"\"\"\n",
    "        image_tensor = input_image.unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(image_tensor).logits\n",
    "        pred_class = output.argmax(dim=1).item() if target_class is None else target_class\n",
    "        \n",
    "        # Clear gradients\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Backward pass\n",
    "        class_loss = output[0, pred_class]\n",
    "        class_loss.backward()\n",
    "        \n",
    "        # Get gradients and activations\n",
    "        gradients = self.gradients[0]\n",
    "        activations = self.activations[0]\n",
    "        \n",
    "        # Global average pooling of gradients\n",
    "        weights = torch.mean(gradients, dim=(2, 3))\n",
    "        \n",
    "        # Weight the activations by the gradients\n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n",
    "        for i, w in enumerate(weights[0]):\n",
    "            cam += w * activations[0, i, :, :]\n",
    "            \n",
    "        # ReLU and normalization\n",
    "        cam = torch.maximum(cam, torch.tensor(0))\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "        \n",
    "        # Resize to original image size\n",
    "        cam = cv2.resize(cam.detach().cpu().numpy(), \n",
    "                        (input_image.shape[2], input_image.shape[3]))\n",
    "        \n",
    "        return cam, pred_class\n",
    "\n",
    "class RetinalExplainer:\n",
    "    def __init__(self, classifier_model):\n",
    "        self.grad_cam = GradCAM(classifier_model)\n",
    "        \n",
    "    def explain(self, image_path, save_path=None):\n",
    "        \"\"\"\n",
    "        Generate and optionally save explanation visualization\n",
    "        \n",
    "        Args:\n",
    "            image_path: path to the input image\n",
    "            save_path: path to save the visualization (optional)\n",
    "        \n",
    "        Returns:\n",
    "            superimposed_img: numpy array of the heatmap superimposed on original image\n",
    "        \"\"\"\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        preprocess = self.grad_cam.model.transform\n",
    "        input_tensor = preprocess(image).unsqueeze(0)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam, pred_class = self.grad_cam.generate_cam(input_tensor[0])\n",
    "        \n",
    "        # Convert CAM to heatmap\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        \n",
    "        # Load original image and resize to match heatmap\n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image = cv2.resize(original_image, (cam.shape[1], cam.shape[0]))\n",
    "        \n",
    "        # Superimpose heatmap on original image\n",
    "        superimposed_img = cv2.addWeighted(original_image, 0.7, heatmap, 0.3, 0)\n",
    "        \n",
    "        if save_path:\n",
    "            cv2.imwrite(save_path, superimposed_img)\n",
    "            \n",
    "        return superimposed_img, pred_class\n",
    "\n",
    "    def plot_explanation(self, image_path):\n",
    "        \"\"\"\n",
    "        Plot the original image, heatmap, and superimposed visualization\n",
    "        \"\"\"\n",
    "        # Generate explanation\n",
    "        superimposed_img, pred_class = self.explain(image_path)\n",
    "        \n",
    "        # Load original image\n",
    "        original_image = cv2.imread(image_path)\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Plot original image\n",
    "        ax1.imshow(original_image)\n",
    "        ax1.set_title('Original Image')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Plot superimposed visualization\n",
    "        ax2.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title(f'Grad-CAM Visualization\\nPredicted Class: {pred_class}')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming we have a trained classifier\n",
    "    classifier = RetinalClassifier()\n",
    "    explainer = RetinalExplainer(classifier.model)\n",
    "    \n",
    "    # Generate and display explanation for a sample image\n",
    "    fig = explainer.plot_explanation('path/to/sample/image.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
